{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semconstmining.declare.enums import Template\n",
    "import logging\n",
    "import pandas as pd\n",
    "from semconstmining.mining.extraction.extractionhandler import DeclareExtractor\n",
    "from semconstmining.parsing.label_parser.nlp_helper import NlpHelper\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from semconstmining.config import Config\n",
    "from semconstmining.main import get_resource_handler\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "                    level=logging.WARNING)\n",
    "\n",
    "MODEL_COLLECTION = \"#####\"\n",
    "\n",
    "conf = Config(Path(os.getcwd()).parents[1].resolve(), MODEL_COLLECTION)\n",
    "conf.CONSTRAINT_TYPES_TO_IGNORE = [ct for ct in conf.CONSTRAINT_TYPES_TO_IGNORE if ct not in [Template.INIT.templ_str, Template.END.templ_str, Template.CHOICE.templ_str]]\n",
    "print(conf.CONSTRAINT_TYPES_TO_IGNORE)\n",
    "\n",
    "nlp_helper = NlpHelper(conf)\n",
    "resource_handler = get_resource_handler(conf, nlp_helper)\n",
    "extractor = DeclareExtractor(config=conf, resource_handler=resource_handler)\n",
    "dfs = [extractor.discover_plain_control_flow_constraints(t, no_events=True) for t in resource_handler.bpmn_logs.reset_index().itertuples()]\n",
    "all_constraints = pd.concat(dfs).astype({conf.LEVEL: \"category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_handler.bpmn_model_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from semconstmining.mining.aggregation.subsumptionanalyzer import SubsumptionAnalyzer\n",
    "all_constraints[conf.SUPPORT] = 1\n",
    "all_constraints[conf.OBJECT] = \"\"\n",
    "activity_constraints = all_constraints\n",
    "#activity_constraints[conf.CONSTRAINT_STR] = activity_constraints[conf.CONSTRAINT_STR].str.replace(\"|\", \"\")\n",
    "#activity_constraints[conf.CONSTRAINT_STR] = activity_constraints[conf.CONSTRAINT_STR].str.strip()\n",
    "#activity_constraints = activity_constraints[[conf.MODEL_ID,conf.CONSTRAINT_STR]]\n",
    "# Group by 'conf.MODEL_ID' and generate a list of 'conf.CONSTRAINT_STR' elements for each group\n",
    "grouped = activity_constraints.groupby(conf.MODEL_ID)\n",
    "dfs = []\n",
    "for group_id, group in tqdm(grouped):\n",
    "    if group_id == \"1bd1ef6b99d6492c9d533f9120462f18\":\n",
    "        print(group[conf.CONSTRAINT_STR])\n",
    "    # event_elms = resource_handler.bpmn_model_elements[(resource_handler.bpmn_model_elements[conf.MODEL_ID] == group_id) & (resource_handler.bpmn_model_elements[conf.ELEMENT_CATEGORY].str.contains(\"Event\"))][conf.CLEANED_LABEL].values\n",
    "    # event_elms = [e for e in event_elms if e != \"\"]\n",
    "    # # print(event_elms)\n",
    "    # consts = group[(~group[conf.LEFT_OPERAND].isin(event_elms)) & (~group[conf.RIGHT_OPERAND].isin(event_elms))]\n",
    "    # if len(consts) < len(group):\n",
    "    #     print(group_id + \": Skipping \" + str(len(group) - len(consts)) + \"constraints due to event labels\")\n",
    "    subsumption_analyzer = SubsumptionAnalyzer(conf, group)\n",
    "    subsumption_analyzer.check_refinement()\n",
    "    subsumption_analyzer.check_subsumption()\n",
    "    subsumption_analyzer.check_equal()\n",
    "    dfs.append(subsumption_analyzer.constraints[~subsumption_analyzer.constraints[conf.REDUNDANT]])\n",
    "refined = pd.concat(dfs)\n",
    "refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = refined.groupby(conf.MODEL_ID).agg({conf.CONSTRAINT_STR: list})\n",
    "\n",
    "# Rename the 'conf.CONSTRAINT_STR' column to 'constraints'\n",
    "grouped = grouped.rename(columns={conf.CONSTRAINT_STR: 'constraints'})\n",
    "\n",
    "# Reset the index to turn the 'conf.MODEL_ID' column into a regular column\n",
    "grouped = grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped[\"constraints\"].values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.to_pickle(MODEL_COLLECTION + \"_model_id_to_constraints.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
