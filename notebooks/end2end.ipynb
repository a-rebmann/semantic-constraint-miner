{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca38dbdf-2059-4000-ba53-858712b91df5",
   "metadata": {},
   "source": [
    "# Current Process-Atom Research Code (main end-to-end pipeline)\n",
    "\n",
    "### Main issues\n",
    "* Individual components that fulfil tasks are intertwined\n",
    "  * strong focus on individual methods (bert tagger, sent transformer) for assessing semantic similarity/matching\n",
    "  * all implemented using Pandas Dataframes -> not modular enough...\n",
    "\n",
    "### High-level TODOs\n",
    "* Create proper data model for atoms of different types and atoms that are instantiated for a certain event log\n",
    "* Need to decouple different sub-tasks\n",
    "* Make them more modular\n",
    "  * Extraction per Atom Type\n",
    "  * Extraction per Model\n",
    "  * Matching function as parameters\n",
    "  * ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9126f1-507a-4d22-9db1-5c447b519237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semconstmining.parsing.label_parser.nlp_helper import NlpHelper\n",
    "from semconstmining.selection.instantiation.recommendation_config import RecommendationConfig\n",
    "from semconstmining.selection.consistency.consistency import ConsistencyChecker\n",
    "from semconstmining.config import Config\n",
    "from semconstmining.main import get_resource_handler, get_or_mine_constraints, get_parts_of_constraints, get_log_and_info, compute_relevance_for_log, recommend_constraints_for_log, add_original_labels, check_constraints, get_violation_to_cases\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d5bba-f9ff-4035-bb89-5430a5e02e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE = \"BPI_Challenge_2019.xes\"\n",
    "MODEL_COLLECTION = \"semantic_sap_sam_filtered\"\n",
    "\n",
    "config = Config(Path(os.getcwd()).parents[0].resolve(), MODEL_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54616903-79fd-436f-b1fe-ed59e2052b04",
   "metadata": {},
   "source": [
    "### Load the necessary NLP stuff for matching\n",
    "\n",
    "loads \n",
    "* SpaCy, \n",
    "* GloVe embeddings,\n",
    "* A custom pretrained transformer for analyzing activitiy labels (extracting objects and actions)\n",
    "* a pretrained sentence transformer to assess similarities between process atom components and event log components\n",
    "* WordNet for synonym checking of actions (such as 'assess' and 'check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92904b70-0b2d-4f49-9a1d-1d38d5d3f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_helper = NlpHelper(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3298849-9c45-4524-932a-18364b175f65",
   "metadata": {},
   "source": [
    "### Loads and processes models so process atoms can be extracted/mined from them \n",
    "\n",
    "* transforms models into Petri nets (PNs) and plays them out (generated activity sequences)\n",
    "* filters out models that are unsuitable (e.g., unsound)\n",
    "* parses and stores activity labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b65398-2bea-4dbc-bcd8-40184008d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_handler = get_resource_handler(config, nlp_helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38b93e-15cc-4ad8-894e-85cc3050f3d3",
   "metadata": {},
   "source": [
    "### Extracts process atoms from activity sequences.\n",
    "* Extracts four types of process atoms from the activity sequence set that has been produced per model\n",
    "  * Activity\n",
    "  * Multi-object (projects the activity sequences to object types contained in the labels)\n",
    "  * Object (projects the activity sequences to actiions for each distinct object type found in the labels)\n",
    "  * Resource (uses pool and lane info stored in a role_to_activity mapping in the resource handler)\n",
    "* Extraction is based on Declare mining (extends an existing Python lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34dd7b-2434-46e5-9912-0c16e83224d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_constraints = get_or_mine_constraints(config, resource_handler, min_support=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715487d8-850b-47ab-b035-ba9245c1a4b1",
   "metadata": {},
   "source": [
    "### Pre-computes embeddings\n",
    "of natural language process atom components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3bcd1-218f-4aaf-b384-3e5232d554a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_helper.pre_compute_embeddings(sentences=get_parts_of_constraints(config, all_constraints))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c94753d-577c-4983-8447-46810dcf7179",
   "metadata": {},
   "source": [
    "### Load the event log from disk \n",
    "(this part will be handled via API to PINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd5ed5-d34a-4ecc-9a48-b63ce68ec10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log, log_info = get_log_and_info(config, nlp_helper, LOG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6015b990-bb80-4ffa-bf84-2e2c079d333e",
   "metadata": {},
   "source": [
    "### Compute the relevance/semantic similarity between log components (events/activities and parts of events/activities) and process atom components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1665d67e-3286-487e-9726-5b6a72f262da",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_constraints_with_relevance = compute_relevance_for_log(config, all_constraints, nlp_helper, LOG_FILE, pd_log=event_log, precompute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca9b1c8-35e4-4aa3-8b93-3930d8ed42ec",
   "metadata": {},
   "source": [
    "### Instantiate the constraints based on their relevance -> generate queries that match the \"language of the event log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689639d3-464d-4301-9f54-36e07bb6c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_config = RecommendationConfig(config, semantic_weight=0.9, top_k=250)\n",
    "recommended_constraints = recommend_constraints_for_log(config, rec_config, all_constraints_with_relevance, nlp_helper, LOG_FILE, pd_log=event_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780d588-49cb-48ab-acf7-edda7e196fa9",
   "metadata": {},
   "source": [
    "### Check if there are obvious contradictions between pairwise constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad596093-4696-4524-ad4d-049ce48bbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_checker = ConsistencyChecker(config)\n",
    "# Check for trivial inconsistencies\n",
    "consistent_recommended_constraints = consistency_checker.check_trivial_consistency(recommended_constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25062efc-6ba9-4bb9-87c1-55f4e2e402e2",
   "metadata": {},
   "source": [
    "### Add the original labels to process atoms so connection to events is prossible \n",
    "(since before the labels were normalized/preprocessed) Should happen much ssoner already when matching/instantiating atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a68e27-63c4-42be-830c-ef9b51b429b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistent_recommended_constraints = add_original_labels(config, consistent_recommended_constraints, log_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb79e6-c314-4e05-9cd7-4acc1bf3bf43",
   "metadata": {},
   "source": [
    "### Identify violations: needs to be handled via queries to PINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a7517-5a21-49c4-9606-936227fb36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "violations = check_constraints(config, LOG_FILE, consistent_recommended_constraints, nlp_helper, pd_log=event_log, with_id=True)\n",
    "violations_to_cases = get_violation_to_cases(config, violations, with_id=True)\n",
    "violation_df = pd.DataFrame.from_records([{\"violation\": violation, \"num_violations\": len(cases), \"cases\": cases} for violation, cases in violations_to_cases.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903dfb3b-3eb9-4a41-926a-aaa23df9355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0f8a3-d371-4672-b330-0669ac662d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(violation_df) > 0:\n",
    "    violation_df = pd.merge(consistent_recommended_constraints.reset_index(), violation_df,\n",
    "                         left_on=config.RECORD_ID, right_on='violation', how='inner')\n",
    "violation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c3cc5-bffc-42c0-8432-055bbd6ceb17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
